import signal, sys, time, numpy as np
from audio.recorder import AudioRecorder
from audio.stream_buffer import StreamBuffer
from stt.whisper_engine import transcribe_once
from llm.deepseek_client import DeepSeekClient
from ui.console_ui import ConsoleUI
from rich.console import Console

console = Console()
recorder = AudioRecorder()
buffer = StreamBuffer()
llm = DeepSeekClient()

def start():
    recorder.start_recording()
    buffer.clear()
    console.print("[cyan]ğŸ¤ å¼€å§‹å½•éŸ³ï¼Œå†æŒ‰ç©ºæ ¼ç»“æŸ[/cyan]")

def stop():
    recorder.stop_recording()
    console.print("[yellow]â¹ï¸ å½•éŸ³ç»“æŸï¼Œæ•´åˆæ–‡æœ¬â€¦[/yellow]")
    audio_np = np.array(recorder.full_audio, dtype="int16")
    if not audio_np.size:
        console.print("[red]æœªæ£€æµ‹åˆ°è¯­éŸ³[/red]")
        return
    text = transcribe_once(audio_np)
    ConsoleUI.print_asr(text)
    final = ConsoleUI.ask_edit(text)
    console.print(f"[ASK] {final}")
    for token in llm.chat(final):
        ConsoleUI.print_assistant(token)
    console.print()

ui = ConsoleUI(start, stop)

def sigint_handler(*_):
    console.print("\n[red]é€€å‡º[/red]")
    sys.exit(0)

signal.signal(signal.SIGINT, sigint_handler)

if __name__ == "__main__":
    recorder.start()          
    console.print("ç¨‹åºå·²å¯åŠ¨ï¼ŒæŒ‰ç©ºæ ¼å¼€å§‹/åœæ­¢å½•éŸ³ï¼ŒCtrl+C é€€å‡º", style="bold green")
    while True:
        time.sleep(0.1)